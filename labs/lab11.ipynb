{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La finalidad de este laboratorio es tener un mejor manejo de las herramientas que nos ofrece Scikit-Learn, como los _transformers_ y _pipelines_.  Usaremos el dataset [The Current Population Survey (CPS)](https://www.openml.org/d/534) que consiste en predecir el salario de una persona en función de atributos como la educación, experiencia o edad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como siempre, un pequeño análisis descriptivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = fetch_openml(data_id=534, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = survey.data[survey.feature_names]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe(include=\"all\").T.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = survey.target\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la posterior partición _train/test_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "(1 pto)\n",
    "\n",
    "_One-Hot Encode_ es una técnica que a partir de una _feature_ categórica generar múltiples columnas, una por categoría.\n",
    "\n",
    "* Define el transformador `ohe_sex` utilizando `OneHotEncoder` con atributos `drop=\"if_binary\"` y `sparse=False`, luego ajusta y transforma el dataframe `X` solo con la columna `SEX`.\n",
    "* Define el transformador `ohe_race` utilizando `OneHotEncoder` con atributos `drop=\"if_binary\"` y `sparse=False`, luego ajusta y transforma el dataframe `X` solo con la columna `RACE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_sex = OneHotEncoder(drop = 'if_binary', sparse = False)\n",
    "ohe_sex.fit_transform(X['SEX'].to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_race = OneHotEncoder(drop = 'if_binary', sparse = False)\n",
    "ohe_race.fit_transform(X['RACE'].to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pregunta:__ ¿Por qué las transformaciones resultantes tiene diferente cantidad de columnas?\n",
    "\n",
    "__Respuesta:__ Porque tienen distintas cantidades de categorías, y la cantidad de columnas se corresponde con la cantidad de categorías (a excepción de las categorías binarias, donde solo hay una columna ya que esta contiene toda la información)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "(1 pto)\n",
    "\n",
    "Realizar _One-Hot-Encoding_ para cada una de las columnas categóricas y luego unirlas en un nuevo array o dataframe es tedioso, poco escablable y probablemente conlleve a errores. La función `make_column_transformer` permite automatizar este proceso en base a aplicar transformadores a distintas columnas.\n",
    "\n",
    "* `categorical_columns` debe ser una lista con todos los nombres de columnas categóricas del dataframe `X`.\n",
    "* `numerical_columns` debe ser una lista con todos los nombres de columnas numéricas del dataframe `X`.\n",
    "* Define `preprocessor` utilizando `make_column_transformer` tal que:\n",
    "    - A las columnas categóricas se les aplique `OneHotEncoder` con el argumento `drop=\"if_binary\"`\n",
    "    - El resto de las columnas se mantenga igual. Hint: Revisar la documentación del argumento `remainder`.\n",
    "* Finalmente define  `X_processed` al ajustar y transformar el dataframe `X` utilizando `preprocessor` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "categorical_columns = ['SOUTH', 'SEX', 'UNION', 'RACE', 'OCCUPATION', 'SECTOR', 'MARR']\n",
    "numerical_columns = ['EDUCATION', 'EXPIRIENCE', 'AGE']\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (OneHotEncoder(drop='if_binary'),categorical_columns),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "print(X_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_processed tiene {X_processed.shape[0]} filas y {X_processed.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "(1 pto)\n",
    "\n",
    "Sucede un fenómeno similar al aplicar transformaciones al vector de respuesta. En ocasiones es necesario transformarlo pero que las predicciones sean en la misma escala original. `TransformedTargetRegressor` juega un rol clave, pues los insumos necesarios son: un estimador, la función y la inversa para aplicar al vector de respuesta.\n",
    "\n",
    "Define `ttr` como un `TransformedTargetRegressor` tal que:\n",
    "* El regresor sea un modelo de regresión Ridge y parámetro de regularización `1e-10`.\n",
    "* La función para transformar sea logaritmo base 10. Hint: `NumPy` es tu amigo.\n",
    "* La función inversa sea aplicar `10**x`. Hint: Revisa el módulo `special` de `SciPy` en la sección de _Convenience functions_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttr = TransformedTargetRegressor(\n",
    "    regressor = Ridge(alpha = 1e-10),\n",
    "    func = np.log10,\n",
    "    inverse_func = sp.special.exp10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajusta el modelo con los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lamentablemente lanza un error :(\n",
    "\n",
    "Prueba lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttr.fit(X_train.select_dtypes(include=\"number\"), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pregunta:__ ¿Por qué falló el primer ajusto? ¿Qué tiene de diferente el segundo?\n",
    "\n",
    "__Respuesta:__ Porque tiene columnas categóricas, a las que no se les puede aplicar log10, la segunda selecciona solo aquellas columnas que tienen valores numéricos y por eso no tira error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "(1 pto)\n",
    "\n",
    "Ahora agreguemos todos los ingredientes a la juguera.\n",
    "\n",
    "* Define `model` utilizando `make_pipeline` con los insumos `preprocessor` y `ttr`.\n",
    "* Ajusta `model` con los datos de entrenamiento.\n",
    "* Calcula el error absoluto medio con los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    ttr\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mae = median_absolute_error(y_pred, y_test)\n",
    "\n",
    "print(f\"El error absoluto medio obtenido es {mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
